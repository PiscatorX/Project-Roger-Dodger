{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from load_data import GetZeoliteTsv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#zeolite datafile exported from excel\n",
    "zeolite_fname = \"C:\\\\Users\\\\DrewX\\\\Documents\\\\Project-Roger-Dodger\\\\Python-ML\\\\zeolites database catagories V 2.txt\"\n",
    "#filename for datafile\n",
    "zeolite_outfile = \"ZeoX_Final_encodedx.tsv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#open the raw tsv data file \n",
    "#the file has to be correctly formatted with columns headers  \n",
    "zeolite_fileObj = open(zeolite_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#create an instance to start processing the datafile\n",
    "getZeo = GetZeoliteTsv(zeolite_fileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adsorbent</th>\n",
       "      <th>SA</th>\n",
       "      <th>Vmicro</th>\n",
       "      <th>Vmeso</th>\n",
       "      <th>pore_size</th>\n",
       "      <th>Si_Al</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>C1</th>\n",
       "      <th>...</th>\n",
       "      <th>Ri3</th>\n",
       "      <th>adsorbate</th>\n",
       "      <th>dipole_moment</th>\n",
       "      <th>chemical_hardness</th>\n",
       "      <th>kinetic_diameter</th>\n",
       "      <th>C_0</th>\n",
       "      <th>solvent</th>\n",
       "      <th>oil_adsorbent_ratio</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CuAgY</td>\n",
       "      <td>591.00</td>\n",
       "      <td>0.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.43</td>\n",
       "      <td>Na+</td>\n",
       "      <td>Ag+</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>291</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>125</td>\n",
       "      <td>50</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CuAgY</td>\n",
       "      <td>591.00</td>\n",
       "      <td>0.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.43</td>\n",
       "      <td>Na+</td>\n",
       "      <td>Ag+</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>420</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>125</td>\n",
       "      <td>50</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CuAgY</td>\n",
       "      <td>591.00</td>\n",
       "      <td>0.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.43</td>\n",
       "      <td>Na+</td>\n",
       "      <td>Ag+</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>556</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>125</td>\n",
       "      <td>50</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CuAgY</td>\n",
       "      <td>591.00</td>\n",
       "      <td>0.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.43</td>\n",
       "      <td>Na+</td>\n",
       "      <td>Ag+</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>719</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>125</td>\n",
       "      <td>50</td>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CuAgY</td>\n",
       "      <td>591.00</td>\n",
       "      <td>0.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.43</td>\n",
       "      <td>Na+</td>\n",
       "      <td>Ag+</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>833</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>125</td>\n",
       "      <td>50</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>CuHY</td>\n",
       "      <td>399.29</td>\n",
       "      <td>0.190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Na+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1100</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>CuHY</td>\n",
       "      <td>399.29</td>\n",
       "      <td>0.190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Na+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1219</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>CuHY</td>\n",
       "      <td>399.29</td>\n",
       "      <td>0.190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Na+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1321</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>CuHY</td>\n",
       "      <td>399.29</td>\n",
       "      <td>0.190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Na+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1418</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>CuHY</td>\n",
       "      <td>399.29</td>\n",
       "      <td>0.190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Na+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cu+</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3.0401</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1508</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Adsorbent      SA  Vmicro  Vmeso  pore_size  Si_Al   m1   m2   m3     C1  \\\n",
       "0       CuAgY  591.00   0.295    NaN        NaN   2.43  Na+  Ag+  Cu+  0.020   \n",
       "1       CuAgY  591.00   0.295    NaN        NaN   2.43  Na+  Ag+  Cu+  0.020   \n",
       "2       CuAgY  591.00   0.295    NaN        NaN   2.43  Na+  Ag+  Cu+  0.020   \n",
       "3       CuAgY  591.00   0.295    NaN        NaN   2.43  Na+  Ag+  Cu+  0.020   \n",
       "4       CuAgY  591.00   0.295    NaN        NaN   2.43  Na+  Ag+  Cu+  0.020   \n",
       "..        ...     ...     ...    ...        ...    ...  ...  ...  ...    ...   \n",
       "351      CuHY  399.29   0.190    NaN        NaN   3.40  Na+  NaN  Cu+  0.357   \n",
       "352      CuHY  399.29   0.190    NaN        NaN   3.40  Na+  NaN  Cu+  0.357   \n",
       "353      CuHY  399.29   0.190    NaN        NaN   3.40  Na+  NaN  Cu+  0.357   \n",
       "354      CuHY  399.29   0.190    NaN        NaN   3.40  Na+  NaN  Cu+  0.357   \n",
       "355      CuHY  399.29   0.190    NaN        NaN   3.40  Na+  NaN  Cu+  0.357   \n",
       "\n",
       "     ...   Ri3  adsorbate  dipole_moment  chemical_hardness  \\\n",
       "0    ...  0.77         TP           0.57             3.0401   \n",
       "1    ...  0.77         TP           0.57             3.0401   \n",
       "2    ...  0.77         TP           0.57             3.0401   \n",
       "3    ...  0.77         TP           0.57             3.0401   \n",
       "4    ...  0.77         TP           0.57             3.0401   \n",
       "..   ...   ...        ...            ...                ...   \n",
       "351  ...  0.77         TP           0.51             3.0401   \n",
       "352  ...  0.77         TP           0.51             3.0401   \n",
       "353  ...  0.77         TP           0.51             3.0401   \n",
       "354  ...  0.77         TP           0.51             3.0401   \n",
       "355  ...  0.77         TP           0.51             3.0401   \n",
       "\n",
       "     kinetic_diameter    C_0      solvent  oil_adsorbent_ratio Temp  Capacity  \n",
       "0                 0.77   291  cyclohexane                  125   50      16.0  \n",
       "1                 0.77   420  cyclohexane                  125   50      24.0  \n",
       "2                 0.77   556  cyclohexane                  125   50      31.0  \n",
       "3                 0.77   719  cyclohexane                  125   50      34.3  \n",
       "4                 0.77   833  cyclohexane                  125   50      35.5  \n",
       "..                 ...   ...          ...                  ...  ...       ...  \n",
       "351               0.77  1100  cyclohexane                   20   25       9.8  \n",
       "352               0.77  1219  cyclohexane                   20   25      10.5  \n",
       "353               0.77  1321  cyclohexane                   20   25      10.9  \n",
       "354               0.77  1418  cyclohexane                   20   25      11.2  \n",
       "355               0.77  1508  cyclohexane                   20   25      11.4  \n",
       "\n",
       "[356 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check of datatypes\n",
    "#important to recognise that datatypes are detected from the files\n",
    "#this step alsos makes the string variables as categorical variables\n",
    "getZeo.set_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'ZeoX_Final_encoded.miss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-83c61660b582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#this counts the missing records per column and saves them to provided filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgetZeo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissingness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ZeoX_Final_encoded.miss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Project-Roger-Dodger\\Python-ML\\load_data.py\u001b[0m in \u001b[0;36mmissingness\u001b[1;34m(self, miss_outfile)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mdf_miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_miss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mdf_miss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmiss_outfile\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf_miss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py3k\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3382\u001b[0m         )\n\u001b[0;32m   3383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3384\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3385\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3386\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py3k\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py3k\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py3k\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    640\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'ZeoX_Final_encoded.miss'"
     ]
    }
   ],
   "source": [
    "#this counts the missing records per column and saves them to provided filename\n",
    "getZeo.missingness(\"ZeoX_Final_encoded.miss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#take note of number of columns\n",
    "getZeo.zeolite_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Drops empty columns inplace\n",
    "getZeo.zeolite_df.dropna(how='all', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Very that columns have indeed been lost\n",
    "getZeo.zeolite_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getZeo.missingness(\"ZeoX_Final_encoded.miss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getZeo.GroupMeanImputation('Adsorbent','Vmicro')\n",
    "getZeo.MeanImputation('Vmicro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getZeo.GroupMeanImputation('Adsorbent','Vmeso')\n",
    "getZeo.MeanImputation('Vmeso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "getZeo.GroupMeanImputation('Adsorbent','pore_size')\n",
    "getZeo.MeanImputation('pore_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "getZeo.GroupMeanImputation('Adsorbent','pore_size')\n",
    "getZeo.MeanImputation('pore_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check categorical variables\n",
    "getZeo.df_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#convert the categorical variables to intergers also known as one-hot-encoding\n",
    "#https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40\n",
    "getZeo.encode_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metal in ['C1', 'C2', 'C3', 'x1', 'x2', 'x3', 'Ri1', 'Ri2', 'Ri3']:\n",
    "         getZeo.zerofill(metal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#save the new data to a tsv file\n",
    "getZeo.save_zeo(\"ZeoX_Final_encoded.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#get our dataframe \n",
    "zeolite_final  = getZeo.zeolite_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#check our dataframe\n",
    "zeolite_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#We extract our data features \n",
    "#attributes \n",
    "y = zeolite_final.loc[:,\"Capacity\"].values\n",
    "#labels\n",
    "X = zeolite_final.drop([\"Capacity\"], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Split our data into training and test dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Standardize features by removing the mean and scaling to unit variasnce\n",
    "sc = StandardScaler()\n",
    "#https://datascience.stackexchange.com/questions/12321/whats-the-difference-between-fit-and-fit-transform-in-scikit-learn-models#:~:text=%22fit%22%20computes%20the%20mean%20and,both%20at%20the%20same%20time.\n",
    "#This should not make much of a difference but its good practice\n",
    "#TO DO\n",
    "#Compare accuracy with and without scaling\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "n_trees = 10\n",
    "n_feat = 31\n",
    "#max_features=n_features,\n",
    "regressor = RandomForestRegressor(n_estimators = 10, min_samples_split = 2, min_samples_leaf = 1, max_features = 37, max_depth = 28, random_state=1000)\n",
    "#TO DO\n",
    "#increase n_estimators\n",
    "#run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame.from_dict({'y_pred': y_pred, 'y_test': y_test, 'errors': y_pred - y_test, 'abs_errors': abs(y_pred - y_test)})\n",
    "plot_data.to_csv(\"RF_model_performance.tsv\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = metrics.mean_squared_error(y_test, y_pred, squared = False)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 =  metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = pd.DataFrame.from_dict({\"n_feat\": [n_feat],\n",
    "                                    \"n_trees\":[n_trees],\n",
    "                                     \"mae\": [mae], \n",
    "                                     \"mse\": [mse], \n",
    "                                     \"rmse\":[rmse],\n",
    "                                     \"r2\":[r2],\n",
    "                                     \"mape\":[mape]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Correlation coefficient (R): {:.4f} \".format(r_value))\n",
    "print(\"p-value : {}\".format(p_value))\n",
    "print(\"Intercept: {:.4f}\".format(intercept))\n",
    "print(\"Slope: {:.4f}\".format(slope))\n",
    "print(\"std_error: {:.4f}\".format(std_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.regplot(y=\"y_pred\",\n",
    "                 x=\"y_test\", \n",
    "                 color=\"g\", \n",
    "                 marker=\"+\",\n",
    "                 line_kws={'label':'$r^2$ = {:.2f}'.format(r_value**2)},\n",
    "                 data = plot_data)\n",
    "\n",
    "plt.ylabel('Predicted adsorptive capacity (mgS/g)')\n",
    "plt.xlabel('Experimental adsorptive capacity (mgS/g)')\n",
    "ax.legend(loc=9)\n",
    "plt.savefig('traning_r2.pdf', format='pdf', dpi=1200)\n",
    "plt.show()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(data = {\"features\":zeolite_final.drop([\"Capacity\"], axis = 1).columns, \"importance\":regressor.feature_importances_} )\n",
    "feature_importance.to_csv(\"RFX_feature_importance.tsv\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?regressor.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance[\"importance\"] = round(feature_importance[\"importance\"],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(feature_importance.importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(regressor, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_PI = pd.DataFrame(data = {\"features\":zeolite_final.drop([\"Capacity\"], axis = 1).columns, \n",
    "                                          \"importance_mean\":result.importances_mean,\n",
    "                                          \"importance_std\": result.importances_std} )\n",
    "feature_importance_PI.to_csv(\"RF_feature_importance_PI.tsv\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?result.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_PI[\"importance_mean\"] = round(feature_importance_PI[\"importance_mean\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_PI.sort_values(\"importance_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "# Number of trees in random forest\n",
    "n_estimators = list(range(1,20))\n",
    "# Number of features to consider at every split\n",
    "max_features = list(range(1,40))\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 40, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1, 2, 4]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators=n_trees, max_features=n_feat, random_state=42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
